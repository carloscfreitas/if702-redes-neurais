{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Risco de Crédito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('nbagg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import talos as ta\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "from numpy import concatenate, vstack, argmin\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir DataFrame a partir da base de dados.\n",
    "data_set = pd.read_csv('data/TRN', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO01</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_7</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "      <th>IND_BOM_1_1</th>\n",
       "      <th>IND_BOM_1_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDEX</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135098</td>\n",
       "      <td>1</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273504</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281910</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225741</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480403</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 245 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7     IDADE  SEXO_1  \\\n",
       "INDEX                                                               \n",
       "0         1     1     1     0     0     0     0  0.135098       1   \n",
       "1         1     0     1     0     0     1     0  0.273504       1   \n",
       "2         1     0     1     0     0     1     0  0.281910       0   \n",
       "3         1     1     1     0     0     0     0  0.225741       0   \n",
       "4         1     1     0     0     0     1     0  0.480403       0   \n",
       "\n",
       "       NIVEL_RELACIONAMENTO_CREDITO01     ...       CEP4_7  CEP4_8  CEP4_9  \\\n",
       "INDEX                                     ...                                \n",
       "0                            0.222222     ...            0       0       1   \n",
       "1                            0.111111     ...            0       1       0   \n",
       "2                            1.000000     ...            1       1       0   \n",
       "3                            0.111111     ...            1       1       0   \n",
       "4                            0.111111     ...            1       1       1   \n",
       "\n",
       "       CEP4_10  CEP4_11  CEP4_12  CEP4_13  CEP4_14  IND_BOM_1_1  IND_BOM_1_2  \n",
       "INDEX                                                                         \n",
       "0            1        0        1        1        1            0            1  \n",
       "1            1        1        0        0        0            1            0  \n",
       "2            0        0        0        1        0            1            0  \n",
       "3            1        1        0        1        0            1            0  \n",
       "4            0        0        1        0        1            1            0  \n",
       "\n",
       "[5 rows x 245 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibe as 5 primeiras linhas da base de dados.\n",
    "data_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa as classes em DataFrames distintos.\n",
    "class_1_df = data_set.loc[data_set['IND_BOM_1_2'] == 0] # Bom pagador.\n",
    "class_2_df = data_set.loc[data_set['IND_BOM_1_2'] == 1] # Mau pagador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa \"features\" dos \"targets\" para cada classe, transformando-os em numpy arrays.\n",
    "class_1_X = class_1_df.iloc[:, :-2].values\n",
    "class_1_y = class_1_df.iloc[:, -1].values\n",
    "\n",
    "class_2_X = class_2_df.iloc[:, :-2].values\n",
    "class_2_y = class_2_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treino: 50%, Validação: 25%, Teste: 25% (para ambas as classes).\n",
    "class_1_X_train, class_1_X_test, class_1_y_train, class_1_y_test = train_test_split(\n",
    "    class_1_X, class_1_y, test_size=0.25, random_state=42, stratify=class_1_y)\n",
    "\n",
    "class_1_X_train, class_1_X_val, class_1_y_train, class_1_y_val = train_test_split(\n",
    "    class_1_X_train, class_1_y_train, test_size=(1./3), random_state=42, stratify=class_1_y_train)\n",
    "\n",
    "class_2_X_train, class_2_X_test, class_2_y_train, class_2_y_test = train_test_split(\n",
    "    class_2_X, class_2_y, test_size=0.25, random_state=42, stratify=class_2_y)\n",
    "\n",
    "class_2_X_train, class_2_X_val, class_2_y_train, class_2_y_val = train_test_split(\n",
    "    class_2_X_train, class_2_y_train, test_size=(1./3), random_state=42, stratify=class_2_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatena os arrays de treinamento das classes (features e targets).\n",
    "X_train = vstack((class_1_X_train, class_2_X_train))\n",
    "y_train = concatenate([class_1_y_train, class_2_y_train])\n",
    "\n",
    "# Concatena os arrays de validação das classes (features e targets).\n",
    "X_val = vstack((class_1_X_val, class_2_X_val))\n",
    "y_val = concatenate([class_1_y_val, class_2_y_val])\n",
    "\n",
    "# Concatena os arrays de teste das classes (features e targets).\n",
    "X_test = vstack((class_1_X_test, class_2_X_test))\n",
    "y_test = concatenate([class_1_y_test, class_2_y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over-sampling os conjuntos de treinamento e validação da classe 2 (minoritária).\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "X_val_resampled, y_val_resampled = ros.fit_resample(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aleatorização.\n",
    "X_train, y_train = shuffle(X_train_resampled, y_train_resampled, random_state=42)\n",
    "X_val, y_val = shuffle(X_val_resampled, y_val_resampled, random_state=42)\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de features do nosso data set.\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "# Aqui criamos o esboço da rede.\n",
    "classifier = Sequential()\n",
    "\n",
    "# Agora adicionamos a primeira camada escondida e função de ativação.\n",
    "# Por ser a primeira camada adicionada à rede, precisamos especificar\n",
    "# a dimensão de entrada (número de features do data set).\n",
    "classifier.add(Dense(64, activation='tanh', input_dim=input_dim))\n",
    "\n",
    "# Em seguida adicionamos a camada de saída. Como nosso problema é binário só precisamos de\n",
    "# 1 neurônio com função de ativação sigmoidal. A partir da segunda camada adicionada keras já\n",
    "# consegue inferir o número de neurônios de entrada e nós não precisamos mais especificar.\n",
    "classifier.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Por fim compilamos o modelo especificando um otimizador, a função de custo, e opcionalmente\n",
    "# métricas para serem observadas durante treinamento.\n",
    "sgd = optimizers.SGD(lr=0.05)\n",
    "classifier.compile(optimizer=sgd, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Para treinar a rede passamos o conjunto de treinamento e especificamos o tamanho do mini-batch,\n",
    "# o número máximo de épocas, e opcionalmente callbacks. No seguinte exemplo utilizamos early\n",
    "# stopping para interromper o treinamento caso a performance não melhore em um conjunto de validação.\n",
    "history = classifier.fit(X_train, y_train, batch_size=64, epochs=200, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_final_losses(history):\n",
    "    \"\"\"Função para extrair o melhor loss de treino e validação.\n",
    "    \n",
    "    Argumento(s):\n",
    "    history -- Objeto retornado pela função fit do keras.\n",
    "    \n",
    "    Retorno:\n",
    "    Dicionário contendo o melhor loss de treino e de validação baseado \n",
    "    no menor loss de validação.\n",
    "    \"\"\"\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    idx_min_val_loss = argmin(val_loss)\n",
    "    return {'train_loss': train_loss[idx_min_val_loss], 'val_loss': val_loss[idx_min_val_loss]}\n",
    "\n",
    "def plot_training_error_curves(history):\n",
    "    \"\"\"Função para plotar as curvas de erro do treinamento da rede neural.\n",
    "    \n",
    "    Argumento(s):\n",
    "    history -- Objeto retornado pela função fit do keras.\n",
    "    \n",
    "    Retorno:\n",
    "    A função gera o gráfico do treino da rede e retorna None.\n",
    "    \"\"\"\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(train_loss, label='Train')\n",
    "    ax.plot(val_loss, label='Validation')\n",
    "    ax.set(title='Training and Validation Error Curves', xlabel='Epochs', ylabel='Loss (MSE)')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "def compute_performance_metrics(y, y_pred_class, y_pred_scores=None):\n",
    "    accuracy = accuracy_score(y, y_pred_class)\n",
    "    recall = recall_score(y, y_pred_class)\n",
    "    precision = precision_score(y, y_pred_class)\n",
    "    f1 = f1_score(y, y_pred_class)\n",
    "    performance_metrics = (accuracy, recall, precision, f1)\n",
    "    if y_pred_scores is not None:\n",
    "        auroc = roc_auc_score(y, y_pred_scores)\n",
    "        aupr = average_precision_score(y, y_pred_scores)\n",
    "        performance_metrics = performance_metrics + (auroc, aupr)\n",
    "    return performance_metrics\n",
    "\n",
    "def print_metrics_summary(accuracy, recall, precision, f1, auroc=None, aupr=None):\n",
    "    print()\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"Accuracy:\", value=accuracy))\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"Recall:\", value=recall))\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"Precision:\", value=precision))\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"F1:\", value=f1))\n",
    "    if auroc is not None:\n",
    "        print(\"{metric:<18}{value:.4f}\".format(metric=\"AUROC:\", value=auroc))\n",
    "    if aupr is not None:\n",
    "        print(\"{metric:<18}{value:.4f}\".format(metric=\"AUPR:\", value=aupr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_training_error_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fazer predições no conjunto de teste\n",
    "y_pred_scores = classifier.predict(X_test)\n",
    "y_pred_class = classifier.predict_classes(X_test, verbose=0)\n",
    "\n",
    "## Matriz de confusão\n",
    "print('Matriz de confusão no conjunto de teste:')\n",
    "print(confusion_matrix(y_test, y_pred_class))\n",
    "\n",
    "## Resumo dos resultados\n",
    "losses = extract_final_losses(history)\n",
    "print()\n",
    "print(\"{metric:<18}{value:.4f}\".format(metric=\"Train Loss:\", value=losses['train_loss']))\n",
    "print(\"{metric:<18}{value:.4f}\".format(metric=\"Validation Loss:\", value=losses['val_loss']))\n",
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_pred_class, y_pred_scores)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (redes-neurais)",
   "language": "python",
   "name": "if702-redes-neurais"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
